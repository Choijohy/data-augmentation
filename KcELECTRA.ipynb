{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#우울증상 발화문 분류 모델\n",
        "사용모델: KcELECTRA(이준범, 2021)\n",
        "아래 영화리뷰 감정분석 구현 코드를 토대로, 프로젝트에 맞게 일부 수정한 코드입니다. 코드 출처: https://velog.io/@seoyeon96/PLM%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%95%9C%EA%B5%AD%EC%96%B4-%ED%98%90%EC%98%A4-%ED%91%9C%ED%98%84-%ED%83%90%EC%A7%80-6.-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95"
      ],
      "metadata": {
        "id": "makG0lSWwavR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KcELECTRA 인용 표기\n",
        "@misc{lee2021kcelectra,\n",
        "  author = {Junbum Lee},\n",
        "  title = {KcELECTRA: Korean comments ELECTRA},\n",
        "  year = {2021},\n",
        "  publisher = {GitHub},\n",
        "  journal = {GitHub repository},\n",
        "  howpublished = {\\url{https://github.com/Beomi/KcELECTRA}}\n",
        "}"
      ],
      "metadata": {
        "id": "bXOW_2vQRaM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaGhgfeTplQo",
        "outputId": "c2c529a8-aee9-4a04-ba83-9de891a19adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import_ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW4U2nofsq8H",
        "outputId": "76449282-fa2e-4af5-91b1-d1f827b415f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import_ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (5.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (67.7.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (3.0.38)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (2.14.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import_ipynb) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (5.3.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import_ipynb) (2.16.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (23.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import_ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import_ipynb) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import_ipynb) (3.3.0)\n",
            "Installing collected packages: jedi, import_ipynb\n",
            "Successfully installed import_ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/2023_연구학점/jihee/KcELECTRA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qvbAVh_0iJl",
        "outputId": "794df1cf-dd6b-4b4d-ba91-386ef989a59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1d17tbNKxtVyvtWhPZgfbdMPdzKw_uZyc/2023_연구학점/jihee/KcELECTRA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패키지 import\n",
        "import import_ipynb\n",
        "import copy\n",
        "import torch\n",
        "import tqdm\n",
        "import argparse\n",
        "import utils\n",
        "\n",
        "from utils import mask_tokens\n",
        "\n",
        "from typing import Union\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avmKeQ9Gpdfv",
        "outputId": "710a92d4-2ace-42d4-b6ac-f10c4ce51252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from utils.ipynb\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_K2Q8rfrtes7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJuMMSEPonNU"
      },
      "outputs": [],
      "source": [
        "# 모델 import\n",
        "def load_tuned_model(args:argparse.Namespace):\n",
        "    if (torch.cuda.is_available()) and (args.dev_num>=0) and (args.dev_num < torch.cuda.device_count()):\n",
        "        dev = \"cuda:{}\".format(args.dev_num)\n",
        "    else:\n",
        "        dev = \"cpu\"\n",
        "        \n",
        "    model = AutoModelForMaskedLM.from_pretrained(args.tuned_model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tuned_model_path)\n",
        "\n",
        "    model.to(dev)\n",
        "    return model, tokenizer, dev\n",
        "\n",
        "# tokenizer import\n",
        "def tokenize(tokenizer:AutoTokenizer, sent:str):\n",
        "    encoded_dict = tokenizer(\n",
        "        sent,\n",
        "        add_special_tokens = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "    input_id, attention_mask = encoded_dict.input_ids, encoded_dict.attention_mask\n",
        "\n",
        "    return input_id, attention_mask\n",
        "\n",
        "def is_same_token_type(org_token:str, candidate:str) -> bool:\n",
        "    '''\n",
        "    후보 필터링 조건을 만족하는지 확인\n",
        "    - 후보와 원 토큰의 타입을 문장부호와 일반 토큰으로 나누어 같은 타입에 속하는지 확인\n",
        "    '''\n",
        "    res = False\n",
        "    if org_token[0]==\"#\" and org_token[2:].isalpha()==candidate.isalpha():\n",
        "        res = True\n",
        "    elif candidate[0]==\"#\" and org_token.isalpha()==candidate[2:].isalpha():\n",
        "        res = True\n",
        "    elif candidate[0]==\"#\" and org_token[0]==\"#\" and org_token[2:].isalpha()==candidate[2:].isalpha():\n",
        "        res = True\n",
        "    elif org_token.isalpha()==candidate.isalpha() and (candidate[0]!=\"#\" and org_token[0]!=\"#\"):\n",
        "        res = True\n",
        "\n",
        "    return res\n",
        "\n",
        "def candidate_filtering(tokenizer:AutoTokenizer,\n",
        "                        input_ids:list,\n",
        "                        idx:int,\n",
        "                        org:int,\n",
        "                        candidates:Union[list, torch.Tensor]) -> int:\n",
        "    '''\n",
        "    후보 필터링 조건에 만족하는 최적의 후보 선택\n",
        "    1. 원래 토큰과 후보 토큰이 같은 타입(is_same_token_type 참고)\n",
        "    2. 현 위치 앞 혹은 뒤에 동일한 토큰이 있지 않음\n",
        "    '''\n",
        "\n",
        "    org_token = tokenizer.convert_ids_to_tokens([org])[0]\n",
        "    candidate_tokens = tokenizer.convert_ids_to_tokens(candidates.cpu().tolist())\n",
        "\n",
        "    for rank, token in enumerate(candidate_tokens):\n",
        "        if org_token!=token and is_same_token_type(org_token, token):\n",
        "            if input_ids[idx-1]==candidates[rank] or input_ids[idx+1]==candidate_tokens[rank]:\n",
        "                continue\n",
        "            return candidates[rank]\n",
        "\n",
        "    return org\n",
        "\n",
        "def augment_one_sent(model:AutoModelForMaskedLM,\n",
        "                    tokenizer:AutoTokenizer,\n",
        "                    sent:str,\n",
        "                    dev:Union[str, torch.device],\n",
        "                    args:Union[argparse.Namespace, dict]) -> str:\n",
        "    '''\n",
        "    한 문장에 랜덤으로 마스킹을 적용하여 새로운 문장을 생성(증강)\n",
        "\n",
        "    args:\n",
        "        model(AutoModelForMaskedLM)     : finetuned model\n",
        "        tokenizer(AutoTokenizer)\n",
        "        sent(str)                       : 증강할 문장\n",
        "        dev(str or torch.device)\n",
        "        args(argparse.Namespace)\n",
        "            - k(int, default=5) : 사용할 후보의 개수. k개의 후보 적절한 토큰이 없을 경우 원래 토큰 그대로 유지\n",
        "            - threshold(float, default=0.95) : 확률 필터링에 사용할 임계치.\n",
        "                                               마스크에 대해서 특정 후보 토큰을 생성할 확률이 임계치보다 클 경우에는 별도의 필터링 없이 후보를 그대로 사용.\n",
        "           -  mlm_prob(float, default=0.15) : 마스킹 비율\n",
        "        \n",
        "    return:\n",
        "        (str) : 증강 문장\n",
        "    '''\n",
        "\n",
        "    if type(args) == argparse.Namespace:\n",
        "        k = args.k\n",
        "        threshold = args.threshold\n",
        "        mlm_prob = args.mlm_prob\n",
        "        truncate=True\n",
        "    else:\n",
        "        ## type == dict\n",
        "        k = args[\"k\"]\n",
        "        threshold = args[\"threshold\"]\n",
        "        mlm_prob = args[\"mlm_prob\"]\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    input_id, attention_mask  = tokenize(tokenizer, sent)\n",
        "    org_ids = copy.deepcopy(input_id[0])\n",
        "    \n",
        "    masked_input_id, _ = mask_tokens(tokenizer, input_id, mlm_prob, do_rep_random=False)\n",
        "    while masked_input_id.cpu().tolist()[0].count(tokenizer.mask_token_id) < 1:\n",
        "        masked_input_id, _ = mask_tokens(tokenizer, input_id, mlm_prob, do_rep_random=False)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        masked_input_id, attention_mask = masked_input_id.to(dev), attention_mask.to(dev)\n",
        "        output = model(masked_input_id, attention_mask = attention_mask)\n",
        "        logits = output[\"logits\"][0]\n",
        "\n",
        "    copied = copy.deepcopy(masked_input_id.cpu().tolist()[0])\n",
        "    for i in range(len(copied)):\n",
        "        if copied[i] == tokenizer.mask_token_id:\n",
        "            org_token = org_ids[i]\n",
        "            prob = logits[i].softmax(dim=0)\n",
        "            probability, candidates = prob.topk(k)\n",
        "            if probability[0]<threshold:\n",
        "                res = candidate_filtering(tokenizer, copied, i, org_token, candidates)\n",
        "            else:\n",
        "                res = candidates[0]\n",
        "            copied[i] = res\n",
        "\n",
        "    copied = tokenizer.decode(copied, skip_special_tokens=True)\n",
        "\n",
        "    return copied\n",
        "\n",
        "\n",
        "def batch_augment(model:AutoModelForMaskedLM,\n",
        "                tokenizer:AutoTokenizer,\n",
        "                dataset:torch.utils.data.Dataset,\n",
        "                dev:Union[str, torch.device],\n",
        "                args:argparse.Namespace) -> str:\n",
        "    '''\n",
        "    배치 단위의 문장에 랜덤으로 마스킹을 적용하여 새로운 문장 배치를 생성(증강)\n",
        "\n",
        "    args:\n",
        "        model(AutoModelForMaskedLM)\n",
        "        tokenizer(AutoTokenizer)\n",
        "        dataset(torch.utils.data.Dataset)\n",
        "        dev(str or torch.device)\n",
        "        args(argparse.Namespace)\n",
        "            - k(int, default=5)\n",
        "            - threshold(float, default=0.95)\n",
        "           -  mlm_prob(float, default=0.15)\n",
        "        \n",
        "    return:\n",
        "        (list) : 증강한 문장들의 리스트\n",
        "    '''\n",
        "\n",
        "    k = args.k\n",
        "    threshold = args.threshold\n",
        "    mlm_prob = args.mlm_prob\n",
        "    batch_size = args.batch_size\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    augmented_res = []\n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size)\n",
        "    for batch in tqdm.tqdm(dataloader):\n",
        "        #########################################################\n",
        "        # 인풋 문장에 랜덤으로 마스킹 적용\n",
        "        input_ids, attention_masks = batch[0], batch[1]\n",
        "        masked_input_ids, _ = mask_tokens(tokenizer, input_ids, mlm_prob, do_rep_random=False)\n",
        "\n",
        "        masked_input_ids = masked_input_ids.to(dev)\n",
        "        attention_masks = attention_masks.to(dev)\n",
        "        labels = input_ids\n",
        "        #########################################################\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(masked_input_ids, attention_mask = attention_masks)\n",
        "            logits1 = output[\"logits\"]\n",
        "\n",
        "        #########################################################\n",
        "        # 배치 내의 문장 별로 후보 필터링을 적용하고, 결과를 토대로 새로운 문장 생성\n",
        "        augmented1 = []\n",
        "        for sent_no in range(len(masked_input_ids)):\n",
        "            copied = copy.deepcopy(input_ids.cpu().tolist()[sent_no])\n",
        "\n",
        "            for i in range(len(masked_input_ids[sent_no])):\n",
        "                if masked_input_ids[sent_no][i] == tokenizer.pad_token_id:\n",
        "                    break\n",
        "\n",
        "                if masked_input_ids[sent_no][i] == tokenizer.mask_token_id:\n",
        "                    org_token = labels.cpu().tolist()[sent_no][i]\n",
        "                    prob = logits1[sent_no][i].softmax(dim=0)\n",
        "                    probability, candidates = prob.topk(k)\n",
        "                    if probability[0]<threshold:\n",
        "                        res = candidate_filtering(tokenizer, copied, i, org_token, candidates)\n",
        "                    else:\n",
        "                        res = candidates[0]\n",
        "                    copied[i] = res\n",
        "\n",
        "            copied = tokenizer.decode(copied, skip_special_tokens=True)\n",
        "            augmented1.append(copied)\n",
        "        #########################################################\n",
        "        augmented_res.extend(augmented1)\n",
        "\n",
        "    return augmented_res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/2023_연구학점/jihee/EDA_dataset2/symp9/symp9 - Raw.csv',encoding='utf-8')\n",
        "# raw_data = df[df['Label']== 1]\n",
        "raw_data = df['Text'].to_list()"
      ],
      "metadata": {
        "id": "HpSiOAs8oFTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import random\n",
        "\n",
        "    # from data_loader import AugmentDataSet\n",
        "\n",
        "    random.seed(1)\n",
        "\n",
        "    import easydict\n",
        "\n",
        "    args = easydict.EasyDict({\n",
        "        \"tuned_model_path\" : 'seoyeon96/KcELECTRA-MLM',\n",
        "        \"dev_num\" : -1,\n",
        "        \"input_file\" : None,\n",
        "        \"batch_size\" : 1,\n",
        "        \"mlm_prob\" : 0.15,\n",
        "        \"threshold\" :0.95,\n",
        "        \"k\" : 5\n",
        "    })\n",
        "    \n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument(\"--tuned_model_path\", default=\"seoyeon96/KcELECTRA-MLM\", type=str, help=\"Finetuned model path\")\n",
        "    # parser.add_argument(\"--dev_num\", default=-1, type=int, help=\"cuda device number\")\n",
        "    # parser.add_argument(\"--input_file\", default=None, type=str)   # 증강을 적용할 데이터\n",
        "    # parser.add_argument(\"--batch_size\", default=1, type=int)\n",
        "    # parser.add_argument(\"--mlm_prob\", default=0.15, type=float)\n",
        "    # parser.add_argument(\"--threshold\", default=0.95, type=float)\n",
        "    # parser.add_argument(\"--k\", default=5, type=int)\n",
        "\n",
        "    # args = parser.parse_args()\n",
        "    model, tokenizer, dev = load_tuned_model(args) \n",
        "\n",
        "    if args.batch_size > 1:\n",
        "        if args.input_file is None:\n",
        "            raise Exception(\"input_file is None\")\n",
        "        with open(args.input_file, \"r\") as f:\n",
        "            corpus = f.readlines()\n",
        "\n",
        "        dataset = AugmentDataSet(corpus, tokenizer)\n",
        "        augmented = batch_augment(model, tokenizer, dataset, dev, args)\n",
        "    else:\n",
        "        # augmented_list = []\n",
        "        # for i in range(3):\n",
        "        #   for s in raw_data:\n",
        "        #     try:\n",
        "        #       augmented = augment_one_sent(model, tokenizer, s, dev, args)\n",
        "        #     except:\n",
        "        #       augmented = \"\"\n",
        "        #       augmented_list.append(augmented)\n",
        "        #     else:\n",
        "        #       augmented_list.append(augmented)\n",
        "        # print(augmented_list)\n",
        "        input_sen = input(\"INPUT = \").strip()\n",
        "        augmented = augment_one_sent(model, tokenizer, input_sen, dev, args)\n",
        "        print(\"OUTPUT = \", augmented)\n",
        "        print(\"-\"*30)\n",
        "       \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E8L1yQs1kPc",
        "outputId": "88d17656-693b-41eb-ec6e-823acbf3fdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT = 남자 키 159cm외모도 볼품없고동성애자.집안 대대로 가난하고성격도 인프피에 내성적이면서 회피성향짙고 남시선의식 많이하고 자기혐오에 피해의식, 전형적인 자의식과잉에 예민하고 히스테릭함. 한마디로 은은하게 성격이 파탄난 인간의 대명사.장애는 없다. 큰 지병도 없다. 부모에게 학대받고 자라지 않았다.학창시절 교우관계 문제도 없었다.현재 나는 만성적인 우울증과 외모집착,강박을 겪고 있다.내가 노력해서 키가 170이 되고, 이성애자가 되고, 성격을 개조할수 있을까? 그건 내 컨트롤 영역 밖이다.'\n",
            "OUTPUT =  남자 키 159cm외모도 볼품없는동성애자. 집안이 대대로 가난하고성형도 인프랜드에 내성적이면서 회피성향짙고 남시비의식 많이하고 자기혐오에 피해의식, 전형적인 자기식과잉에 예민하고 히스테릭함. 그리고 은은하게 성격이 파탄난 여자의 대명사. 장애는 없다, 심지어 지병도 없다. 부모에게 학대받고 자라지 않았다. 학창시절 교우관계 문제도 없었다. 그래서 나는 만성적인 우울증과 외모 패착, 강박을 겪고 있다. 내가 노력해서 키가 170이 되고, 이성병자가 되고. 성격을 컨트롤할수 있을까? 그건 스스로 컨트롤 영역 밖이다,.\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(augmented_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWKna6xdor4x",
        "outputId": "63c3c60d-219c-4e55-e7d6-87775c0988e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data = pd.DataFrame(zip(augmented_list))\n",
        "augmented_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_ZvL7LuPytpl",
        "outputId": "a969703b-83d7-4d3a-da6e-f53a924422f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0\n",
              "0    중3남자가학력대학교홈페이지에 있는 우울증테스트를 해봤는데 심각한 우울증이 예상된 사...\n",
              "1    우울증 약으로 약을 복용하고 있고, 이년째 복용중입니다요즘 개인적으로 힘든일이 있어...\n",
              "2    20대 초반의 여대생입니다. 자살충동이 자꾸 일어나 너무 괴롭습니다. 지금은 휴학중...\n",
              "3    층간소음으로 인해 우울증에 시달리다가정신과 치료로도 치유가안되서 자살하게되면신반사망...\n",
              "4    안녕하세요.. 저 중학교 2학년 인데요 지금 공부 스트레스 때문에 미치겠어요ㅠㅠ 그...\n",
              "..                                                 ...\n",
              "292  어른들은 그랬다. 자라면서 상처를 받고, 그 상처가 아물면서 딱지를지고, 그 딱지로...\n",
              "293  우울증인것같은데확실하진 않고원래 어렸을 때부터 죽고 싶다는 생각 자주 했었는데그런 ...\n",
              "294  나는 사랑이 넘치는 사람이다많은 사람들에게 이걸 주고 싶었고 줬다처음엔 돌아오는게 ...\n",
              "295  난 왜 이렇게까지 자기연민에 빠져서 혼자 행복해버릴까 솔직히 객관적으로 봤을때 내가...\n",
              "296  몇 주 동안 이유없이 우울하다. 내가 뭐하는지도 모르겠고, 나는 항상 부족하고, 남...\n",
              "\n",
              "[297 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-964f34ce-5daa-47ab-8ca8-e9fa7f2d63d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>중3남자가학력대학교홈페이지에 있는 우울증테스트를 해봤는데 심각한 우울증이 예상된 사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>우울증 약으로 약을 복용하고 있고, 이년째 복용중입니다요즘 개인적으로 힘든일이 있어...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20대 초반의 여대생입니다. 자살충동이 자꾸 일어나 너무 괴롭습니다. 지금은 휴학중...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>층간소음으로 인해 우울증에 시달리다가정신과 치료로도 치유가안되서 자살하게되면신반사망...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>안녕하세요.. 저 중학교 2학년 인데요 지금 공부 스트레스 때문에 미치겠어요ㅠㅠ 그...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>어른들은 그랬다. 자라면서 상처를 받고, 그 상처가 아물면서 딱지를지고, 그 딱지로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>우울증인것같은데확실하진 않고원래 어렸을 때부터 죽고 싶다는 생각 자주 했었는데그런 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>나는 사랑이 넘치는 사람이다많은 사람들에게 이걸 주고 싶었고 줬다처음엔 돌아오는게 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>난 왜 이렇게까지 자기연민에 빠져서 혼자 행복해버릴까 솔직히 객관적으로 봤을때 내가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>몇 주 동안 이유없이 우울하다. 내가 뭐하는지도 모르겠고, 나는 항상 부족하고, 남...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>297 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-964f34ce-5daa-47ab-8ca8-e9fa7f2d63d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-964f34ce-5daa-47ab-8ca8-e9fa7f2d63d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-964f34ce-5daa-47ab-8ca8-e9fa7f2d63d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data.to_csv('/content/drive/MyDrive/2023_연구학점/jihee/KcELECTRA/augmented/augmented9.csv')"
      ],
      "metadata": {
        "id": "5kVvd4qwy7Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTTc1rQwzR4H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}